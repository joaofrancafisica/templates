{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob #to read the files\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from scipy.interpolate import interp1d\n",
    "import os.path \n",
    "from tabulate import tabulate #to export in table format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 0.5 * RBF(length_scale=1, length_scale_bounds=(1, 20)) + WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-5,0.5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = np.linspace(-20, 50, 70 + 1)\n",
    "wave = np.linspace(2000, 9200, 720 + 1)\n",
    "save_path = '/home/joao/Documentos/PCA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"names.txt\")\n",
    "lines = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    if line.startswith('#'): continue\n",
    "    co=line.rstrip().replace('INDEF','Nan').split()\n",
    "\n",
    "    training_set.append(co[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SN2012fr',\n",
       " 'SN2005cf',\n",
       " 'SN2001V',\n",
       " 'SN2003du',\n",
       " 'SN2011fe',\n",
       " 'SN2014J',\n",
       " 'SN1994D',\n",
       " 'SN2004dt',\n",
       " 'SN2012dn',\n",
       " 'SN2002bo',\n",
       " 'SN1998aq',\n",
       " 'SN2007le',\n",
       " 'SN2007af',\n",
       " 'SN1999aa',\n",
       " 'SN2000cx',\n",
       " 'SN2005hk',\n",
       " 'SN2003cg',\n",
       " 'SN2009dc',\n",
       " 'SN1999ac',\n",
       " 'SN1999by',\n",
       " 'SN2008ar',\n",
       " 'SN2005M',\n",
       " 'SN2001ep']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SN2012fr\n",
      "SN2005cf\n",
      "SN2001V\n",
      "SN2003du\n",
      "SN2011fe\n",
      "SN2014J\n",
      "SN1994D\n",
      "SN2004dt\n",
      "SN2012dn\n",
      "SN2002bo\n",
      "SN1998aq\n",
      "SN2007le\n",
      "SN2007af\n",
      "SN1999aa\n",
      "SN2000cx\n",
      "SN2005hk\n",
      "SN2003cg\n",
      "SN2009dc\n",
      "SN1999ac\n",
      "SN1999by\n",
      "SN2008ar\n",
      "SN2005M\n",
      "SN2001ep\n"
     ]
    }
   ],
   "source": [
    "for j in range(0,len(training_set)):\n",
    "\n",
    "    list_data = [[[],[]] for y in range(0,721)]\n",
    "    \n",
    "    sn_names=glob.glob(\"/home/joao/Documentos/templates/data_ext/\"+training_set[j]+\"*\"+\".dat\")\n",
    "    #sn_names=glob.glob(\"/home/joao/Documentos/templates/data_ext/\"+\"SN2014J\"+\"*\"+\".dat\")\n",
    "    #print(sn_names)\n",
    "    \n",
    "    for p in range(0,len(sn_names)):\n",
    "\n",
    "        sn_names[p] = sn_names[p][41:]\n",
    "    \n",
    "    \n",
    "    print(training_set[j])\n",
    "    \n",
    "    #print(sn_names)\n",
    "    \n",
    "    if len(sn_names) > 3:\n",
    "        \n",
    "        for i in range(0,len(sn_names)):\n",
    "\n",
    "            #y = []\n",
    "            z = []\n",
    "\n",
    "            file = open(sn_names[i])\n",
    "            lines = file.readlines()\n",
    "            file.close()\n",
    "\n",
    "            for line in lines:\n",
    "                if line.startswith('#'): continue\n",
    "                co=line.rstrip().replace('INDEF','Nan').split()\n",
    "\n",
    "                #y.append(co[0])\n",
    "                z.append(co[1])\n",
    "        \n",
    "\n",
    "            #y = np.array(y, dtype=float)\n",
    "            z = np.array(z, dtype=float)\n",
    "            #print(z)\n",
    "            \n",
    "            \n",
    "            for l in range(0,len(z)):\n",
    "                \n",
    "                if z[l] < 10**(-64):\n",
    "                    \n",
    "                     z[l] = 0\n",
    "            \n",
    "            \n",
    "            timetemp = lines[0]\n",
    "            timetemp = timetemp[:-1]\n",
    "            timetemp = float(timetemp[1:])\n",
    "            \n",
    "            for jj in range(0,len(z)):\n",
    "                \n",
    "                list_data[jj][0].append([timetemp])\n",
    "                list_data[jj][1].append(z[jj])\n",
    "\n",
    "            #print(i)\n",
    "            \n",
    "        Export = []\n",
    "\n",
    "        for jj in range(0,len(list_data)):\n",
    "\n",
    "            teste = all(v == 0 for v in list_data[jj][1])\n",
    "            \n",
    "            if teste == False:\n",
    "                #print(list_data[jj][1])\n",
    "                ff = max(list_data[jj][1])\n",
    "                #print(ff)\n",
    "                list_data[jj][1] = list_data[jj][1]/ff\n",
    "                \n",
    "                #print(list_data[jj][0])\n",
    "                #print(list_data[jj][1])\n",
    "                \n",
    "                #gp = GaussianProcessRegressor(kernel=kernel, alpha=np.var(list_data[jj][1])).fit(list_data[jj][0], list_data[jj][1])\n",
    "                gp = GaussianProcessRegressor(kernel=kernel, alpha=0.0).fit(list_data[jj][0], list_data[jj][1])\n",
    "                \n",
    "                #val_score = gp.score(yy, zz)\n",
    "                #score.append(val_score)\n",
    "\n",
    "                y_mean = gp.predict(X_[:, np.newaxis])\n",
    "                \n",
    "                for l in range(0,len(y_mean)):\n",
    "\n",
    "                    Export.append(y_mean[l]*ff)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                y_mean = [0 for y in range(0,71)]\n",
    "                #print(len(y_mean), len(X_))\n",
    "                \n",
    "                for l in range(0,len(y_mean)):\n",
    "\n",
    "                    Export.append(y_mean[l])\n",
    "          \n",
    "        table = []\n",
    "        for l in range(0,len(Export)):\n",
    "            table.append((Export[l],training_set[j]))\n",
    "\n",
    "\n",
    "        name_of_file = training_set[j]\n",
    "\n",
    "        completeName = os.path.join(save_path, name_of_file+\".dat\")\n",
    "\n",
    "        f = open(completeName, 'w')\n",
    "        f.write(tabulate(table, tablefmt=\"plain\"))\n",
    "        f.close()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
